{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain.agents import create_json_agent\n",
    "from langchain_community.agent_toolkits import JsonToolkit\n",
    "from langchain_community.tools.json.tool import JsonSpec\n",
    "from langchain_openai import OpenAI\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(dotenv_path=\".env\")\n",
    "with open(\"defillama_pools.json\") as f:\n",
    "    data = json.load(f)\n",
    "json_spec = JsonSpec(dict_=data, max_value_length=4000)\n",
    "json_toolkit = JsonToolkit(spec=json_spec)\n",
    "\n",
    "json_agent_executor = create_json_agent(\n",
    "    llm=OpenAI(temperature=0), toolkit=json_toolkit, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_agent_executor.run(\"Uniswap V3的USDC-WETH池的APY是多少？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_agent_executor.run(\"binance cex的tvl有多少\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://api.llama.fi/protocols\"\n",
    "headers = {\"accept\": \"*/*\"}\n",
    "response = requests.get(url, headers=headers)\n",
    "data = response.json()\n",
    "print(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    PromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.agents.format_scratchpad.openai_tools import (\n",
    "    format_to_openai_tool_messages,\n",
    ")\n",
    "from langchain_community.tools.convert_to_openai import format_tool_to_openai_tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents.output_parsers.openai_tools import OpenAIToolsAgentOutputParser\n",
    "from langchain.agents import AgentExecutor\n",
    "from my_langchain_anthropic.experimental import ChatAnthropicTools\n",
    "from langchain_core.runnables import ConfigurableField\n",
    "from anthropic_tools import (\n",
    "    AnthropicToolsAgentOutputParser,\n",
    "    format_to_anthropic_tool_messages,\n",
    ")\n",
    "from langchain_core.utils.function_calling import convert_to_openai_function\n",
    "\n",
    "url = \"https://api.llama.fi/protocols\"\n",
    "headers = {\"accept\": \"*/*\"}\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "# 确保请求成功\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    json_data = {}\n",
    "    for d in data:\n",
    "        # d[\"chains\"] = d[\"chainTvls\"]\n",
    "        json_data[d[\"name\"]] = d\n",
    "    json_spec = JsonSpec(dict_=json_data, max_value_length=4000)\n",
    "    json_toolkit = JsonToolkit(spec=json_spec)\n",
    "    tools = json_toolkit.get_tools()\n",
    "else:\n",
    "    raise Exception(\"请求失败，状态码：\", response.status_code)\n",
    "\n",
    "llm_agent = ChatAnthropicTools(\n",
    "    model=\"claude-3-opus-20240229\",\n",
    "    # max_tokens=,\n",
    "    temperature=0.7,\n",
    "    # anthropic_api_key=os.environ.get(\"ANTHROPIC_API_KEY\", \"not_provided\"),\n",
    "    streaming=True,\n",
    "    verbose=True,\n",
    ").configurable_alternatives(  # This gives this field an id\n",
    "    # When configuring the end runnable, we can then use this id to configure this field\n",
    "    ConfigurableField(id=\"llm\"),\n",
    "    default_key=\"anthropic_claude_3_opus\",\n",
    "    openai_gpt_3_5_turbo_1106=ChatOpenAI(\n",
    "        model=\"gpt-3.5-turbo-1106\",\n",
    "        verbose=True,\n",
    "        streaming=True,\n",
    "        temperature=0.9,\n",
    "    ),\n",
    "    openai_gpt_4_turbo_preview=ChatOpenAI(\n",
    "        temperature=0.9,\n",
    "        model=\"gpt-4-turbo-preview\",\n",
    "        verbose=True,\n",
    "        streaming=True,\n",
    "    ),\n",
    ")\n",
    "system_message = \"\"\"You are a very useful assistant. \n",
    "\n",
    "Please first use json_spec_list_keys(data) to find the relevant keys, and then call json_spec_get_value with the most relevant key.\n",
    "\n",
    "For example, when json_spec_get_value(data[\"key1\"]) returns a KeyError, please call json_spec_list_keys(data) again to find a key2 related to \"key1\", and then call json_spec_get_value(data[\"key2\"]) again.\n",
    "\n",
    "In the JSON file, key `chains` is an array of string. It means the project has tvl on those chains.\n",
    "\n",
    "And the key 'chainTvls' is a obj, it means the tvl on chains.\n",
    "\n",
    "`change_1h` represents the change of tvl within 1 hour.\n",
    "`change_1d` represents the change of tvl within 1 day. \n",
    "`change_d` represents the change of tvl within 7 days.\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_message),\n",
    "        (\"human\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ").configurable_alternatives(\n",
    "    which=ConfigurableField(\"llm\"),\n",
    "    default_key=\"anthropic_claude_3_opus\",\n",
    "    openai_gpt_4_turbo_preview=ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            SystemMessagePromptTemplate.from_template(template=system_message),\n",
    "            HumanMessagePromptTemplate.from_template(\"{input}\"),\n",
    "            MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "        ]\n",
    "    ),\n",
    "    openai_gpt_3_5_turbo_1106=ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            SystemMessagePromptTemplate.from_template(template=system_message),\n",
    "            HumanMessagePromptTemplate.from_template(\"{input}\"),\n",
    "            MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "agent = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"agent_scratchpad\": lambda x: format_to_anthropic_tool_messages(\n",
    "            x[\"intermediate_steps\"]\n",
    "        ),\n",
    "    }\n",
    "    | prompt\n",
    "    # | prompt_trimmer # See comment above.\n",
    "    | llm_agent.bind(tools=[convert_to_openai_function(tool) for tool in tools])\n",
    "    | AnthropicToolsAgentOutputParser()\n",
    ").configurable_alternatives(\n",
    "    which=ConfigurableField(\"llm\"),\n",
    "    default_key=\"anthropic_claude_3_opus\",\n",
    "    openai_gpt_4_turbo_preview=(\n",
    "        {\n",
    "            \"input\": lambda x: x[\"input\"],\n",
    "            \"agent_scratchpad\": lambda x: format_to_openai_tool_messages(\n",
    "                x[\"intermediate_steps\"]\n",
    "            ),\n",
    "        }\n",
    "        | prompt\n",
    "        # | prompt_trimmer # See comment above.\n",
    "        | llm_agent.bind(tools=[format_tool_to_openai_tool(tool) for tool in tools])\n",
    "        | OpenAIToolsAgentOutputParser()\n",
    "    ),\n",
    "    openai_gpt_3_5_turbo_1106=(\n",
    "        {\n",
    "            \"input\": lambda x: x[\"input\"],\n",
    "            \"agent_scratchpad\": lambda x: format_to_openai_tool_messages(\n",
    "                x[\"intermediate_steps\"]\n",
    "            ),\n",
    "        }\n",
    "        | prompt\n",
    "        # | prompt_trimmer # See comment above.\n",
    "        | llm_agent.bind(tools=[format_tool_to_openai_tool(tool) for tool in tools])\n",
    "        | OpenAIToolsAgentOutputParser()\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = agent.with_config({\"configurable\": {\"llm\": \"openai_gpt_4_turbo_preview\"}})\n",
    "excutor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True,\n",
    ")\n",
    "res = excutor.invoke({\"input\": \"uniswap tvl的变化\"})\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from defillama_wrapper import DefiLLamaWrapTVLPtotocols\n",
    "\n",
    "tvlWrapper = DefiLLamaWrapTVLPtotocols()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "# agent = tvlWrapper.create_agent().with_config({\"configurable\": {\"llm\": \"openai_gpt_4_turbo_preview\"}})\n",
    "agent = tvlWrapper.create_agent()\n",
    "excutor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tvlWrapper.tools,\n",
    "    verbose=True,\n",
    ")\n",
    "res =  excutor.invoke({\"input\": \"curve tvl的变化\",\"chat_history\":[]})\n",
    "print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
