{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.chat_models import ChatPerplexity\n",
    "from langchain_mistralai import ChatMistralAI\n",
    "from langchain_cohere import ChatCohere\n",
    "\n",
    "\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    ")\n",
    "\n",
    "from langchain_core.runnables import ConfigurableField\n",
    "from langchain_core.runnables import Runnable\n",
    "\n",
    "\n",
    "load_dotenv(\".env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatAnthropic(\n",
    "    model=\"claude-3-opus-20240229\",\n",
    "    max_tokens=2000,\n",
    "    temperature=0.9,\n",
    "    # anthropic_api_key=os.environ.get(\"ANTHROPIC_API_KEY\", \"not_provided\"),\n",
    "    streaming=True,\n",
    "    verbose=True,\n",
    ").configurable_alternatives(  # This gives this field an id\n",
    "    # When configuring the end runnable, we can then use this id to configure this field\n",
    "    ConfigurableField(id=\"llm\"),\n",
    "    # default_key=\"openai_gpt_4_turbo_preview\",\n",
    "    default_key=\"anthropic_claude_3_opus\",\n",
    "    anthropic_claude_3_5_sonnet=ChatAnthropic(\n",
    "        model=\"claude-3-5-sonnet-20240620\",\n",
    "        max_tokens=2000,\n",
    "        temperature=0.9,\n",
    "        # anthropic_api_key=os.environ.get(\"ANTHROPIC_API_KEY\", \"not_provided\"),\n",
    "        streaming=True,\n",
    "        stream_usage=True,\n",
    "        verbose=True,\n",
    "    ),\n",
    "    openai_gpt_3_5_turbo_1106=ChatOpenAI(\n",
    "        model=\"gpt-3.5-turbo-1106\",\n",
    "        verbose=True,\n",
    "        streaming=True,\n",
    "        temperature=0.9,\n",
    "    ),\n",
    "    openai_gpt_4_turbo_preview=ChatOpenAI(\n",
    "        temperature=0.9,\n",
    "        model=\"gpt-4-turbo-preview\",\n",
    "        verbose=True,\n",
    "        streaming=True,\n",
    "    ),\n",
    "    openai_gpt_4o=ChatOpenAI(\n",
    "        temperature=0.9,\n",
    "        model=\"gpt-4o\",\n",
    "        verbose=True,\n",
    "        streaming=True,\n",
    "    ),\n",
    "    openai_gpt_4o_mini=ChatOpenAI(\n",
    "        temperature=0.9,\n",
    "        model=\"gpt-4o-mini\",\n",
    "        verbose=True,\n",
    "        streaming=True,\n",
    "    ),\n",
    "    pplx_sonar_medium_chat=ChatPerplexity(\n",
    "        model=\"sonar-medium-chat\", temperature=0.9, verbose=True, streaming=True\n",
    "    ),\n",
    "    mistral_large=ChatMistralAI(\n",
    "        model=\"mistral-large-latest\", temperature=0.1, verbose=True, streaming=True\n",
    "    ),\n",
    "    command_r_plus=ChatCohere(\n",
    "        model=\"command-r-plus\", temperature=0.9, verbose=True, streaming=True\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.agents import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def news_extractor(title: str, content: str, src_url: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract and analyze the content of a news article.\n",
    "\n",
    "    This function uses a predefined prompt template and language model to analyze\n",
    "    a news article, providing key information extraction, sentiment analysis,\n",
    "    topic classification, relevance analysis, and impact assessment.\n",
    "\n",
    "    Parameters:\n",
    "    title (str): The title of the news article\n",
    "    content (str): The main body content of the news article\n",
    "    src_url (str): The source URL of the news article\n",
    "\n",
    "    Returns:\n",
    "    str: A string containing the analysis results, including key information,\n",
    "         sentiment analysis, topic classification, relevance, and impact assessment\n",
    "    \"\"\"\n",
    "    with open(\"news_analysis_test_prompt.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "        prompt_template = file.read()\n",
    "    chain = ChatPromptTemplate.from_template(prompt_template) | llm | StrOutputParser()\n",
    "    result = chain.invoke(\n",
    "        {\n",
    "            \"title\": title,\n",
    "            \"content\": content,\n",
    "            \"source_url\": src_url,\n",
    "        },\n",
    "        config={\"configurable\": {\"model\": \"anthropic_claude_3_5_sonnet\"}},\n",
    "    )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_agent_executor(llm_agent: Runnable) -> AgentExecutor:\n",
    "    # 从文件加载系统提示\n",
    "    with open(\"system_news_analysis_test_prompt.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "        system_message = file.read()\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system_message),\n",
    "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "            # SystemMessagePromptTemplate.from_template(\n",
    "            #     \"If using the search tool, prefix the string parameter with [S].\"\n",
    "            # ),\n",
    "            (\"human\", \"{input}\"),\n",
    "            MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    from custom_agent_excutor import CustomToolCallingAgentExecutor\n",
    "    from tools_basic import tools\n",
    "\n",
    "    tools += [news_extractor]\n",
    "    executor = CustomToolCallingAgentExecutor(\n",
    "        llm=llm_agent, prompts=prompt, tools=tools\n",
    "    )\n",
    "    return executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "executor = create_agent_executor(llm_agent=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = \"\"\"The news as follow:\n",
    "Title: BitGo计划2025年1月推出创新型稳定币USDS\n",
    "Content: 加密货币托管公司BitGo宣布计划于2025年1月推出一种名为USDS的美元支持稳定币。该稳定币的独特之处在于将为提供流动性的机构提供奖励。\n",
    "\n",
    "BitGo CEO Mike Belshe在Token2049大会前接受CoinDesk采访时表示，USDS将由短期国债、隔夜回购协议和现金支持，类似于市场上的其他稳定币。但与众不同的是，USDS被称为首个\"开放参与\"的稳定币。\n",
    "\n",
    "USDS将通过将储备金产生的部分回报分配给提供流动性的机构来激励它们。BitGo计划在所有主要交易所上市USDS，并目标在明年此时达到100亿美元的资产规模。\n",
    "\n",
    "Source URL:https://x.com/LayerZero_Core/status/1836037465884577894\n",
    "\n",
    "请分析一下这则新闻快讯。\n",
    "\"\"\"\n",
    "\n",
    "streams = executor.astream_events(\n",
    "    {\"input\": news, \"chat_history\": []},\n",
    "    config={\n",
    "        \"configurable\": {\"llm\": \"anthropic_claude_3_5_sonnet\"},\n",
    "    },\n",
    "    version=\"v1\",\n",
    ")\n",
    "buff = \"\"\n",
    "async for chunk in streams:\n",
    "    if chunk[\"event\"] == \"on_chat_model_stream\":\n",
    "        if isinstance(chunk[\"data\"][\"chunk\"].content, str):\n",
    "            buff += chunk[\"data\"][\"chunk\"].content\n",
    "        elif (\n",
    "            isinstance(chunk[\"data\"][\"chunk\"].content, list)\n",
    "            and len(chunk[\"data\"][\"chunk\"].content) > 0\n",
    "            and \"text\" in chunk[\"data\"][\"chunk\"].content[0]\n",
    "        ):\n",
    "            buff += chunk[\"data\"][\"chunk\"].content[0][\"text\"]\n",
    "    print(chunk)\n",
    "print(buff)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
